project_name: "IndraAgent-V11"
run_name: "IndraV11-GPUDistill-Llama"

model:
  vocab_size: 128256 # Llama-3 Vocab
  d_model: 512
  num_layers: 8
  num_heads: 8
  d_ff: 2048
  dropout: 0.1
  max_seq_len: 256
  tie_word_embeddings: true
  gradient_checkpointing: true
  window_size: null

training:
  batch_size: 1
  accumulate_grad_batches: 8
  learning_rate: 3.0e-4
  max_steps: 50000
  warmup_steps: 500
  save_every: 100
  log_every: 10
  use_8bit_optimizer: true
  use_ema: false
  ema_decay: 0.9999

distillation:
  teacher_model: "unsloth/Llama-3.2-1B-Instruct" # Unsloth version is usually ungated
  temperature: 4.0
  alpha_ce: 0.5
  alpha_kd: 0.5
  top_k: 64

data:
  dataset_name: "teknium/OpenHermes-2.5"
  subset_name: null 
  num_proc: 4
  truncation_side: "left"
